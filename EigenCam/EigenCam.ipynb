{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BugvhyRVv8AV",
        "outputId": "3d037468-c27e-4cc2-f68e-6cc3df3e4534"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yyl2KabZzxx_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import mobilenet_v2\n",
        "from torchvision.datasets import FashionMNIST, SVHN\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CAM:\n",
        "    def __init__(self, model, device, preprocess, layer_name=None):\n",
        "        self.layer_name = layer_name if layer_name is not None else self._get_layer_name(model)\n",
        "        self.model = model.eval().to(device)\n",
        "        self.device = device\n",
        "        self.prep = preprocess\n",
        "        self.feature = {}\n",
        "        self._register_hook()\n",
        "\n",
        "    def _get_layer_name(self, model):\n",
        "        layer_name = None\n",
        "        last_name = None\n",
        "        for name, module in model.named_modules():\n",
        "            if hasattr(module, 'inplace'):\n",
        "                module.inplace = False\n",
        "            if isinstance(module, (nn.AdaptiveAvgPool2d, nn.AvgPool2d)):\n",
        "                layer_name = last_name\n",
        "            last_name = name\n",
        "\n",
        "        if layer_name is None:\n",
        "            raise ValueError('No appropriate layer found. Specify a layer for heatmap.')\n",
        "        return layer_name\n",
        "\n",
        "    def _forward_hook(self, module, x, y):\n",
        "        self.feature['output'] = y\n",
        "\n",
        "    def _register_hook(self):\n",
        "        for name, module in self.model.named_modules():\n",
        "            if name == self.layer_name:\n",
        "                module.register_forward_hook(self._forward_hook)\n",
        "                break\n",
        "        else:\n",
        "            raise ValueError(f'No layer named \"{self.layer_name}\" in the model')\n",
        "\n",
        "    def _check(self, feature):\n",
        "        if feature.ndim != 4 or feature.shape[2] * feature.shape[3] == 1:\n",
        "            raise ValueError(f'Invalid feature map shape: {feature.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EigenCAM(CAM):\n",
        "    def get_heatmap(self, img):\n",
        "        img_rgb = img.convert('RGB') if isinstance(img, Image.Image) else Image.fromarray(img).convert('RGB')\n",
        "        tensor = self.prep(img_rgb)[None, ...].to(self.device)\n",
        "        output = self.model(tensor)\n",
        "        feature = self.feature['output']\n",
        "        self._check(feature)\n",
        "\n",
        "        _, _, vT = torch.linalg.svd(feature)\n",
        "        v1 = vT[:, :, 0, :][..., None, :]\n",
        "        cam = feature @ v1.repeat(1, 1, v1.shape[3], 1)\n",
        "        cam = cam.sum(1)\n",
        "        cam = cam - cam.min()\n",
        "        cam = cam / (cam.max() - cam.min())\n",
        "\n",
        "        cam = cam.detach().cpu().numpy().squeeze(0)\n",
        "        cam = cv2.resize(cam, img_rgb.size)\n",
        "        cam = np.uint8(255 * cam)\n",
        "        heatmap = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
        "\n",
        "        img_array = np.array(img_rgb)\n",
        "\n",
        "        overlay = cv2.addWeighted(img_array, 0.7, heatmap, 0.3, 0)\n",
        "\n",
        "        return output, overlay\n"
      ],
      "metadata": {
        "id": "6Gl1UrGrEGME"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(dataset_name):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    model = mobilenet_v2(pretrained=True).eval()\n",
        "    target_layer = 'features'\n",
        "\n",
        "    if dataset_name.lower() == 'fashionmnist':\n",
        "        dataset = FashionMNIST(root='./data', train=False, download=True, transform=preprocess)\n",
        "    elif dataset_name.lower() == 'svhn':\n",
        "        dataset = SVHN(root='./data', split='test', download=True, transform=preprocess)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported dataset. Choose 'FashionMNIST' or 'SVHN'.\")\n",
        "\n",
        "    cam_obj = EigenCAM(model, device, preprocess, layer_name=target_layer)\n",
        "\n",
        "    if not os.path.exists('./drive/MyDrive/output1'):\n",
        "        os.makedirs('./drive/MyDrive/output1')\n",
        "\n",
        "    for i, (img, _) in enumerate(tqdm(dataset, desc=\"Processing images\")):\n",
        "        img = transforms.ToPILImage()(img).convert(\"RGB\")\n",
        "        output, overlay = cam_obj.get_heatmap(img)\n",
        "        overlay_image = Image.fromarray(overlay)\n",
        "        overlay_image.save(f'./drive/MyDrive/output1/heatmap_{i}.png')\n",
        "\n",
        "        if i == 9:\n",
        "            break\n",
        "\n",
        "    print(f\"Processed {i + 1} images.\")\n",
        "\n",
        "main('FashionMNIST')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "dvDmML1ICmVz",
        "outputId": "2beb73cc-b53a-4982-dfb1-d396b5aebefc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images:   0%|          | 0/10000 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "to",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-e8961d179ce2>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processed {i + 1} images.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FashionMNIST'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-e8961d179ce2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Processing images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0moverlay_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moverlay_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./drive/MyDrive/output1/heatmap_{i}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-92dc759a5fe1>\u001b[0m in \u001b[0;36mget_heatmap\u001b[0;34m(self, img_tensor)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEigenCAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mdeprecate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image categories\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_animated\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplural\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: to"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EigenCAM(CAM):\n",
        "    def get_heatmap(self, img_tensor):\n",
        "        img_tensor = img_tensor.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = self.model(img_tensor)\n",
        "            feature = self.feature['output']\n",
        "            self._check(feature)\n",
        "\n",
        "            _, _, vT = torch.linalg.svd(feature)\n",
        "            v1 = vT[:, :, 0, :][..., None, :]\n",
        "            cam = feature @ v1.repeat(1, 1, v1.shape[3], 1)\n",
        "            cam = cam.sum(1, keepdim=True)\n",
        "            cam = cam - cam.min()\n",
        "            cam = cam / (cam.max() - cam.min() + 1e-5)\n",
        "            cam = cam.squeeze().detach().cpu().numpy()\n",
        "            cam = cv2.resize(cam, (224, 224))\n",
        "            cam = np.uint8(255 * cam)\n",
        "            heatmap = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
        "\n",
        "            return output, heatmap"
      ],
      "metadata": {
        "id": "wm-H035UfRI7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(64 * 7 * 7, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7yI6Tq-Y30C9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    model = SimpleCNN().to(device)\n",
        "    dataset = FashionMNIST(root='./data', train=False, download=True, transform=preprocess)\n",
        "    model.eval()\n",
        "    target_layer = 'features.3'\n",
        "    cam_obj = EigenCAM(model, device, preprocess, layer_name=target_layer)\n",
        "\n",
        "    output_dir = './drive/MyDrive/output2'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for i in range(10):\n",
        "        img, _ = dataset[i]\n",
        "        img_unsqueezed = img.unsqueeze(0).to(device)\n",
        "        _, heatmap = cam_obj.get_heatmap(img_unsqueezed)\n",
        "        heatmap = cv2.resize(heatmap, (224, 224))\n",
        "        img_pil = transforms.ToPILImage()(img)\n",
        "        img_pil = img_pil.convert(\"RGB\")\n",
        "        plt.figure()\n",
        "        plt.imshow(img_pil)\n",
        "        plt.imshow(heatmap, cmap='jet', alpha=0.5)\n",
        "        plt.colorbar()\n",
        "        plt.title(f'Image Index: {i}')\n",
        "        plt.axis('off')\n",
        "        # plt.savefig(os.path.join(output_dir, f'heatmap_index_{i}.png'))\n",
        "        plt.close()\n",
        "        img_array = np.array(img_pil)\n",
        "        overlay = cv2.addWeighted(img_array, 0.5, heatmap, 0.5, 0)\n",
        "        overlay_image = Image.fromarray(overlay)\n",
        "        overlay_image.save(os.path.join(output_dir, f'heatmap_{i}.png'))\n",
        "\n",
        "    print(f\"Generated heatmaps for 10 images in {output_dir}\")\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6A-3KnpeSaQ",
        "outputId": "6090c9f9-28fb-4480-9b92-df785e02f6b5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated heatmaps for 10 images in ./drive/MyDrive/output2\n"
          ]
        }
      ]
    }
  ]
}